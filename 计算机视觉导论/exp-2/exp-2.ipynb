{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "SEED = 40\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a573a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 配置信息\n",
    "class Cfg:\n",
    "    data_root = './data'           # MNIST download/cache dir\n",
    "    train_fraction = 0.10          # use 10% of the train split\n",
    "    test_fraction  = 0.10          # use 10% of the test split\n",
    "    train_num_pairs = 10000        # number of training pairs\n",
    "    test_num_pairs  = 2000         # number of test pairs\n",
    "    batch_size = 64\n",
    "    epochs = 50\n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    num_workers = 2\n",
    "    save_dir = './output'\n",
    "    model_name = 'siamese_mnist_same_digit.pth'\n",
    "    # batch_log = 'batch_log.log'\n",
    "    epoch_log = 'epoch_log.csv'\n",
    "\n",
    "os.makedirs(Cfg.save_dir, exist_ok=True)\n",
    "Cfg.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816aac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transforms预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # 归一化[0,1], shape (1,28,28)\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "# 加载MNIST数据集\n",
    "train_dataset = datasets.MNIST(Cfg.data_root, train=True,  download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(Cfg.data_root, train=False, download=True, transform=transform)\n",
    "print(f\"原始训练集大小: {len(train_dataset)}\")\n",
    "print(f\"原始测试集大小: {len(test_dataset)}\")\n",
    "\n",
    "# 抽取10%的数据\n",
    "def sample_dataset(dataset, sample_ratio=0.1):\n",
    "    indices = list(range(len(dataset)))\n",
    "    sampled_indices = random.sample(indices, int(len(dataset) * sample_ratio))\n",
    "    return Subset(dataset, sampled_indices)\n",
    "train_subset = sample_dataset(train_dataset, Cfg.train_fraction)\n",
    "test_subset = sample_dataset(test_dataset, Cfg.test_fraction)\n",
    "print(f\"采样后训练集大小: {len(train_subset)}\")\n",
    "print(f\"采样后测试集大小: {len(test_subset)}\")\n",
    "\n",
    "# 创建配对数据集\n",
    "class MNISTPairsDataset(Dataset):\n",
    "    def __init__(self, subset, num_pairs):\n",
    "        self.subset = subset\n",
    "        self.num_pairs = num_pairs\n",
    "        self.labels = [label for _, label in subset]\n",
    "        self.images = [image for image, _ in subset]\n",
    "        # 生成相同数字的索引映射\n",
    "        label_to_indices = {}\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            if label not in label_to_indices:\n",
    "                label_to_indices[label] = []\n",
    "            label_to_indices[label].append(idx)\n",
    "        # 创建配对\n",
    "        self.pairs = []\n",
    "        self.pair_labels = []\n",
    "        for _ in range(num_pairs // 2):\n",
    "            # 正样本对\n",
    "            label = random.choice(list(label_to_indices.keys()))\n",
    "            if len(label_to_indices[label]) >= 2:\n",
    "                idx1, idx2 = random.sample(label_to_indices[label], 2)\n",
    "                self.pairs.append((idx1, idx2))\n",
    "                self.pair_labels.append(1)\n",
    "            # 负样本对\n",
    "            label1, label2 = random.sample(list(label_to_indices.keys()), 2)\n",
    "            idx1 = random.choice(label_to_indices[label1])\n",
    "            idx2 = random.choice(label_to_indices[label2])\n",
    "            self.pairs.append((idx1, idx2))\n",
    "            self.pair_labels.append(0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx1, idx2 = self.pairs[idx]\n",
    "        x1 = self.images[idx1]\n",
    "        x2 = self.images[idx2]\n",
    "        y = self.pair_labels[idx]\n",
    "        return x1, x2, torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 创建训练和测试配对数据集\n",
    "train_pairs_dataset = MNISTPairsDataset(train_subset, num_pairs=Cfg.train_num_pairs)\n",
    "test_pairs_dataset = MNISTPairsDataset(test_subset, num_pairs=Cfg.test_num_pairs)\n",
    "print(f\"训练配对数据集大小: {len(train_pairs_dataset)}\")\n",
    "print(f\"测试配对数据集大小: {len(test_pairs_dataset)}\")\n",
    "\n",
    "# 检查正负样本比例\n",
    "train_labels = [label for _, _, label in train_pairs_dataset]\n",
    "test_labels = [label for _, _, label in test_pairs_dataset]\n",
    "print(f\"训练集正样本比例: {sum(train_labels) / len(train_labels):.3f}\")\n",
    "print(f\"测试集正样本比例: {sum(test_labels) / len(test_labels):.3f}\")\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(train_pairs_dataset, batch_size=Cfg.batch_size, shuffle=True, num_workers=Cfg.num_workers)\n",
    "test_loader = DataLoader(test_pairs_dataset, batch_size=Cfg.batch_size, shuffle=False, num_workers=Cfg.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdbdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化一些配对样本\n",
    "def show_pairs(ds: MNISTPairsDataset, n=4):\n",
    "    # 创建三列：左图、右图和标签\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=3, figsize=(3, 1*n))\n",
    "    for i in range(n):\n",
    "        x1, x2, y = ds[random.randint(0, len(ds)-1)]\n",
    "        y = int(y.item())\n",
    "        axes[i,0].imshow(x1.squeeze(0), cmap='gray')\n",
    "        axes[i,0].axis('off')\n",
    "        axes[i,1].imshow(x2.squeeze(0), cmap='gray')\n",
    "        axes[i,1].axis('off')\n",
    "        axes[i,2].text(0.5, 0.5, f'Label = {y}', fontsize=16, ha='center', va='center')\n",
    "        axes[i,2].axis('off') \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_pairs(train_pairs_dataset, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim=64):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),   # 1x28x28 -> 16x28x28\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                              # -> 16x14x14\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # -> 32x14x14\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                              # -> 32x7x7\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*7*7, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, emb_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class SiameseSameDigit(nn.Module):\n",
    "    def __init__(self, emb_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = ConvEncoder(emb_dim=emb_dim)\n",
    "        # 使用绝对差和元素级乘积组合特征\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(emb_dim*2, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, 1),  # logit\n",
    "            nn.Sigmoid()  # 输出概率\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.encoder(x1)\n",
    "        z2 = self.encoder(x2)\n",
    "        feat = torch.cat([torch.abs(z1 - z2), z1 * z2], dim=1)\n",
    "        logit = self.head(feat)\n",
    "        return logit.squeeze(1)  # (B,)\n",
    "    \n",
    "    def print_model_parameters(self):\n",
    "        print(f\"{'Layer Name':<40} {'Parameter Shape':<30} {'Param Count':<15}\")\n",
    "        print(\"=\" * 85)\n",
    "        total_params = 0\n",
    "        for name, param in self.named_parameters():\n",
    "            param_count = param.numel() \n",
    "            total_params += param_count\n",
    "            print(f\"{name:<40} {str(list(param.shape)):<30} {param_count:<15}\")\n",
    "        print(\"=\" * 85)\n",
    "        print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "model = SiameseSameDigit(emb_dim=64).to(device)\n",
    "model.print_model_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60078265",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x1, x2, y in loader:\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            outputs = model(x1, x2)\n",
    "            loss = loss_fn(outputs, y)\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            total_correct += (preds == y.view_as(preds)).sum().item()\n",
    "            total += y.size(0)\n",
    "    return total_loss/total, total_correct/total\n",
    "\n",
    "def train(model, train_loader, test_loader, epochs, lr, weight_decay):\n",
    "    # loss_fn = nn.BCEWithLogitsLoss() # 内置sigmoid层\n",
    "    loss_fn = nn.BCELoss() \n",
    "    # optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc': []\n",
    "    }\n",
    "    # log_file_path = os.path.join(Cfg.save_dir, Cfg.batch_log)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "\n",
    "        for b, (x1, x2, y) in enumerate(train_loader):\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x1, x2)\n",
    "            loss = loss_fn(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds = (outputs >= 0.5).float()\n",
    "                correct = (preds == y.view_as(preds)).sum().item()\n",
    "                \n",
    "            # batch_loss = loss.item()\n",
    "            # batch_acc = correct / y.size(0)\n",
    "            epoch_loss += loss.item() * y.size(0)\n",
    "            epoch_correct += correct\n",
    "            epoch_total += y.size(0)\n",
    "            # test_loss_batch, test_acc_batch = evaluate(model, test_loader, loss_fn)\n",
    "            # with open(log_file_path, 'a') as log_file:\n",
    "            #     log_file.write(f\"[epoch {epoch:2d}] [btach_idx {b:3d}] \"+ \n",
    "            #                    f\"batch_loss={batch_loss:.4f} batch_acc={batch_acc:.4f} | \"+\n",
    "            #                    f\"test_loss={test_loss_batch:.4f} test_acc_batch={test_acc_batch:.4f}\\n\")\n",
    "\n",
    "        train_loss = epoch_loss/epoch_total\n",
    "        train_acc  = epoch_correct/epoch_total\n",
    "        test_loss, test_acc = evaluate(model, test_loader, loss_fn)\n",
    "\n",
    "        history['epoch'].append(epoch)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_loss'].append(test_loss)  \n",
    "        history['test_acc'].append(test_acc)\n",
    "\n",
    "        print(f\"[Epoch {epoch:2d}] \"+\n",
    "              f\"train_loss={train_loss:.4f} train_acc={train_acc:.4f} | \"+\n",
    "              f\"test_loss={test_loss:.4f} test_acc={test_acc:.4f}\")\n",
    "\n",
    "    # print(f\"Training log (mini-batch) saved to {log_file_path}\")\n",
    "    hist_df = pd.DataFrame(history)\n",
    "    csv_path = os.path.join(Cfg.save_dir, Cfg.epoch_log)\n",
    "    hist_df.to_csv(csv_path, index=False)\n",
    "    print(f\"Training log (epoch) saved to {csv_path}\")\n",
    "    model_path = os.path.join(Cfg.save_dir, Cfg.model_name)\n",
    "    torch.save(model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "history = train(model, train_loader, test_loader, Cfg.epochs, Cfg.lr, Cfg.weight_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    # 绘制损失和准确率曲线\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # 左图：损失曲线\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0].plot(history['test_loss'], label='Test Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Loss Curves')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # 右图：准确率曲线\n",
    "    axes[1].plot(history['train_acc'], label='Train Acc')\n",
    "    axes[1].plot(history['test_acc'], label='Test Acc')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Accuracy Curves')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x1, x2, y in loader:\n",
    "            x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "            outputs = model(x1, x2)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Different\", \"Same\"])\n",
    "    disp.plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random_pair(model, test_subset):\n",
    "    # 随机挑选两张图片\n",
    "    idx1, idx2 = random.sample(range(len(test_subset)), 2)\n",
    "    x1, label1 = test_subset[idx1]\n",
    "    x2, label2 = test_subset[idx2]\n",
    "    # 将图片转换为批量形式并移动到设备\n",
    "    x1 = x1.unsqueeze(0).to(device)  # (1, 1, 28, 28)\n",
    "    x2 = x2.unsqueeze(0).to(device)  # (1, 1, 28, 28)\n",
    "    # 模型预测\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(x1, x2)  # 输出 logits\n",
    "        pred = 1 if output >= 0.5 else 0  # 二分类预测\n",
    "    # 显示图片和预测结果\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    axes[0].imshow(x1.cpu().squeeze(0).squeeze(0), cmap='gray')\n",
    "    axes[0].set_title(f\"Label: {label1}\")\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(x2.cpu().squeeze(0).squeeze(0), cmap='gray')\n",
    "    axes[1].set_title(f\"Label: {label2}\")\n",
    "    axes[1].axis('off')\n",
    "    result_text = f\"Predicted: {'Same' if pred == 1 else 'Different'} | Actual: {'Same' if label1 == label2 else 'Different'}\"\n",
    "    fig.suptitle(result_text, fontsize=14, y=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "model = torch.load(os.path.join(Cfg.save_dir, Cfg.model_name), map_location=device, weights_only=False)\n",
    "model = model.to(device)\n",
    "predict_random_pair(model, test_subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wjl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
